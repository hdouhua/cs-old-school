# 探索云原生

## 数据持久化

Kubernetes 管理存储资源的 API 对象 PersistentVolume 、 PersistentVolumeClaim 、 StorageClass 。

### Persistent Volume

Pod 里的容器是由镜像产生的，而镜像文件本身是只读的，进程要读写磁盘只能用一个临时的存储空间，一旦 Pod 销毁，临时存储也就会立即回收释放，数据也就丢失了。怎么办呢？

Kubernetes 的 Volume 是对数据存储的一个很好的抽象，它定义了有这么一个“存储卷”，而这个“存储卷”是什么类型、有多大容量、怎么存储，都可以自由发挥。Pod 不需要关心那些专业、复杂的细节，只要设置好 volumeMounts ，就可以把 Volume 加载进容器里使用。顺着 Volume 的概念， Kubernetes 延伸出了 PersistentVolume (PV) 对象，它专门用来表示持久存储设备，但隐藏了存储的底层实现。

作为存储的抽象， PV 实际上就是一些存储设备、文件系统，比如 Ceph、GlusterFS、NFS，甚至是本地磁盘，管理它们已经超出了 Kubernetes 的能力范围，一般会由系统管理员单独维护，然后再在 Kubernetes 里创建对应的 PV。

>PV 属于集群的系统资源，是和 Node 平级的一种对象，Pod 对它没有管理权，只有使用权。

### PersistentVolumeClaim/StorageClass

有了 PV，是否就可以直接在 Pod 里挂载使用了呢？还不行。因为不同存储设备的差异实在是太大了。

于是 Kubernetes 就又增加了两个新对象： PersistentVolumeClaim (PVC) 和 StorageClass，用的还是“中间层”的思想，把存储卷的分配管理过程再次细化。
（简化 Pod 挂载“虚拟盘”的过程， Pod 看不到，也不关心 PV 的实现细节。）

- PersistentVolumeClaim，简称 PVC，从名字上看比较好理解，就是用来向 Kubernetes 申请存储资源的。  
  PVC 是给 Pod 使用的对象，它相当于是 Pod 的代理，代表 Pod 向系统申请 PV。一旦资源申请成功，Kubernetes 就会把 PV 和 PVC 关联在一起，这个动作叫做“绑定”（bind）。

- StorageClass 在 PVC 和 PV 之间充当“协调人”的角色，帮助 PVC 找到合适的 PV。  
  系统里的存储资源非常多，如果要 PVC 去直接遍历查找合适的 PV 也很麻烦，所以就要用到 StorageClass。
  它的作用有点像 IngressClass，它抽象了特定类型的存储系统，归类分组 PV 对象，用来简化 PV 和 PVC 的绑定过程。

<img alt="pv-pvc-storageclass" src="https://static001.geekbang.org/resource/image/5e/22/5e21d007a6152ec9594919300c2b6e22.jpg?wh=1920x1053" width="60%"/><br/>

### YAML 描述 PersistentVolume

Kubernetes 里有很多种类型的 PV，
- 最容易的本机存储 `HostPath`，它和 Docker 里挂载本地目录的 -v 参数非常类似，可以用它来初步认识一下 PV 的用法。

因为 Pod 会在集群的任意节点上运行，所以首先，我们要作为系统管理员在每个节点上创建一个目录，它将会作为本地存储卷挂载到 Pod 里。

```yml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: host-10m-pv

spec:
  storageClassName: host-test
  accessModes:
  - ReadWriteOnce
  capacity:
    storage: 10Mi
  hostPath:
    path: /tmp/host-10m-pv/
```

解释：
- accessModes ：定义了存储设备的访问模式，简单来说就是虚拟盘的读写权限，和 Linux 的文件访问模式差不多，目前 Kubernetes 里有 3 种：
   - ReadWriteOnce：存储卷可读可写，但只能被一个节点上的 Pod 挂载。
   - ReadOnlyMany：存储卷只读不可写，可以被任意节点上的 Pod 多次挂载。
   - ReadWriteMany：存储卷可读可写，也可以被任意节点上的 Pod 多次挂载。

- capacity ：表示存储设备的容量，这里设置为 10MB。
  >Kubernetes 里定义存储容量使用的是国际标准， KB/MB/GB 的基数是 1024，要写成 Ki/Mi/Gi 。

- hostPath ：它指定了存储卷的本地路径，也就是在节点上的目录。

### YAML 描述 PersistentVolumeClaim

定义 PVC 对象，向 Kubernetes 申请存储。

```yml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: host-5m-pvc

spec:
  storageClassName: host-test
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Mi
```

解释：

PVC 的内容与 PV 很像，但它不表示实际的存储，而是一个“申请”或者“声明”， spec 里的字段描述的是对存储的“期望状态”。

PVC 里的 storageClassName 、 accessModes 和 PV 是一样的，但不会有字段 capacity ，而是要用 resources.request 表示希望要有多大的容量。

### 使用 PersistentVolume

创建 PV

```shell
kubectl apply -f host-path-pv.yml
kubectl get pv
#
NAME          CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE
host-10m-pv   10Mi       RWO            Retain           Available           host-test               5m22s
```

创建 PVC

```shell
kubectl apply -f host-path-pvc.yml
kubectl get pvc
#
NAME          STATUS   VOLUME        CAPACITY   ACCESS MODES   STORAGECLASS   AGE
host-5m-pvc   Bound    host-10m-pv   10Mi       RWO            host-test      4s
```

一旦 PVC 对象创建成功， Kubernetes 就会立即通过 StorageClass 、 resources 等条件在集群里查找符合要求的 PV ，如果找到合适的存储对象就会把它俩“绑定”在一起。  
此处 PVC 对象申请的是 5MB，现在系统里只有一个 10MB 的 PV，没有更合适的对象，所以 Kubernetes 也只能把这个 PV 分配出去，多出的容量就算是“福利”了。

如果把 PVC 的申请容量改大一些会怎么样呢？比如改成 100MB？  
会看到 PVC 会一直处于 Pending 状态，这意味着 Kubernetes 在系统里没有找到符合要求的存储，无法分配资源，只能等有满足要求的 PV 才能完成绑定。

### 为 Pod 挂载 PersistentVolume

PV 和 PVC 绑定好了，有了持久化存储，现在可以为 Pod 挂载存储卷。
先要在 `spec.volumes` 定义存储卷，然后在 `containers.volumeMounts` 挂载进容器。
因为用的是 PVC ，所以要在 volumes 里用字段 persistentVolumeClaim 指定 PVC 的名字。

```yml
apiVersion: v1
kind: Pod
metadata:
  name: host-pvc-pod

spec:
  volumes:
  - name: host-pvc-vol
    persistentVolumeClaim:
      claimName: host-5m-pvc

  containers:
    - name: ngx-pvc-pod
      image: nginx:alpine
      ports:
      - containerPort: 80
      volumeMounts:
      - name: host-pvc-vol
        mountPath: /tmp
```

<img alt="pv-pvc-storageclass" src="https://static001.geekbang.org/resource/image/a4/d8/a4d709808a0ef729604c884c50748bd8.jpg?wh=1920x1310" width="60%"/><br/>
(Pod 、PVC 和 PV 的关系)

```shell
kubectl apply -f host-path-pod.yml
kubectl get pod -o wide
#
NAME           READY   STATUS    RESTARTS   AGE   IP            NODE   NOMINATED NODE   READINESS GATES
host-pvc-pod   1/1     Running   0          34s   10.244.1.34   vm2    <none>           <none>
```

可以看到 Pod 被分配到 vm2 节点上，那么 PV 是否确实挂载成功了呢？执行一些命令看看：

```shell
# check the path on bare host directory volume. run the command line on vm2
ll /tmp/
# 可以看到 volume /tmp/host-10m-pv 在 vm2 上自动生成了
drwxr-xr-x  2 root root 4096 Sep 15 14:50 host-10m-pv/

# go into pod
kubectl exec -it host-pvc-pod -- sh
/ # cd tmp
/tmp # echo hello world > a.txt
```

在 vm2 节点检查一下：

```shell
ll /tmp/host-10m-pv/
#
-rw-r--r--  1 root root   12 Sep 15 14:57 a.txt

cat /tmp/host-10m-pv/a.txt
#
hello world
```

可以看到确实在 vm2 节点的本地目录有一个 a.txt 的文件，再对一下时间，就可以确认是刚才在 Pod 里生成的文件。
因为 Pod 产生的数据已经通过 PV 存在了磁盘上，所以如果 Pod 删除后再重新创建，挂载存储卷时会依然使用这个目录，数据保持不变，也就实现了持久化存储。

不过因为这个 PV 是 HostPath 类型，只在本节点存储，如果 Pod 重建时被调度到了其他节点上，那么即使加载了本地目录，也不会是之前的存储位置，持久化功能也就失效了。

>**HostPath 类型的 PV 一般用来做测试。**
